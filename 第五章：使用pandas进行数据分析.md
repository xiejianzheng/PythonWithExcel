# 使用pandas进行数据分析

本章将向你介绍pandas，Python数据分析库，或者————我喜欢这样说————基于Python的具有超级功能的电子表格。                                        
它是如此强大，以至于我合作过的一些公司，成功使用Jupyter笔记本和pandas取代了excel。    
然而，作为本书的读者，我假设你会保留Excel，在这种情况下，panda会作为一个从电子表格中读取和写入数据  
的接口。pandas使在Excel中特别痛苦的任务，更容易、更快、和更少错误。其中一些任务包括从外部来源获取
大数据集、处理统计数据、时序数据和交互式图表。pandas的超级能力是矢量化和数据对齐。正如我们在前面
的章节已经看到的，矢量化允许你编写简洁的、基于NumPy阵列的代码。而数据对齐可以确保在处理多个结果集  
时，不会有数据不匹配。

本章涵盖了整个数据分析过程：它从数据清理和准备过程开始，然后向你展示如何通过聚合、描述性统计、
可视化从更大的数据集中获取意义。在本章的最后，我们将看到如何使用pandas导入和导出数据。但首先，
让我们先来介绍pandas的主要数据结构：数据帧DataFrame和序列Series。  

## 数据帧DataFrame和序列Series

数据帧DataFrame和序列Series是pandas中的核心数据结构。在本节，我会介绍数据帧DataFrame的主要组件：
索引index、列columns和数据data。数据帧DataFrame很像一个二维的NumPy阵列array，但他带有行标签和
列标签，并且每列可以容纳不同的数据类型。通过从数据帧DataFrame中提取单个行或列，你可以得到一个
一维的序列Series。同样的，一个序列类似一个带有标签的NumPy阵列。当你查看图5-1中数据帧的结构时，
不需要很多想象力，就可以看出数据帧DataFrame将成为你的基于Python的电子表格。


图5-1

序列Series是一个带有轴标签的一维阵列。轴Axis编号为0。
数据帧DataFrame是一个带有行列标签的二维阵列，而且它的每一列可以是不同的数据类型。


为了显示从电子表格转换到数据帧DataFrame，是多么容易，思考下面的Excel表格在图5-2，
它显示了在线课程的参与者。你将在配套仓库中找到相应的文件。

为了使Excel表格在Python中可用，先要导入pandas，然后使用它的read_excel函数，它会返回一个
数据帧DataFrame。

In [1]: import pandas as pd
In [2]: pd.read_excel("课程参与者名单.xlsx")

Out[2]:		用户id	姓名	年龄	国家	分数	大陆
	0	1001	马克	55	意大利	4.5	欧洲
	1	1000	约翰	33	美国	6.7	美洲
	2	1002	提姆	41	美国	3.9	美洲
	3	1003	珍妮	12	德国	9.0	欧洲

如果你在Jupyter笔记本中运行这个代码，数据帧DataFrame将被很好地格式化为html表格，
这使它看上去更像电子表格。我将花费第7章的整个篇幅介绍如何用pandas读写Excel文件。
因此这里只是介绍性的例子，向你展示电子表格和数据帧是什么，实际上，它们十分相似。

现在，让我们从头开始重新创建数据帧，而不必从Excel文件中读取它：创建数据帧的一种
方法是，以嵌套列表的方式提供数据，以及索引值和列标签。

In [3]: data = [["马克", 55, "意大利", 4.5, "欧洲"],
		["约翰", 33, "美国", 6.7, "美洲"],
		["提姆", 41, "美国", 3.9, "美洲"],
		["珍妮", 12, "德国", 9.0, "欧洲"]]

	df = pd.DataFrame(data=data,
			  columns=["姓名", "年龄", "国家", "分数", "大陆"],
			  index=[1001, 1000, 1002, 1003])
	df

通过调用info方法，你将会获得一些基础的信息，最重要的是数据点的个数和每一列的
数据类型：
In [4]: df.info()

如果你只对列的数据类型感兴趣，运行df.dtypes()替代。
具有字符串或混合数据类型的列，将具备对象Object数据类型。
让我们现在来更仔细地看看数据帧的索引和列。

### 索引

数据帧的行标签称为索引。如果你不想有一个有意义的索引，那么在构造pandas时，
不要提供它，pandas会自动创建一个从零开始的，整型索引。我们在从Excel文件
读取数据帧DataFrame的第一个示例中看到这一点。索引将使pandas能够更快地索引
数据，并且对很多常用操作（如：合并两个数据帧）至关重要。你可以按如下方法访问
索引对象77：

In [5]: df.index
Out[5]: Int64Index([1001, 1000, 1002, 1003], dtype='int64')

如果索引是有意义的，给索引一个名称，让我们按照excel表格，将其命名为用户ID。

In [6]: df.i 2333333333313333ndex.name = "user_id"
	df

Out[6]: 	姓名	年龄	国家	分数	大陆
	用户ID
	1001	马克	55	意大利	4.5	欧洲
	1000	约翰	33	美国	6.7	美洲
	1002	提姆	41	美国	3.9	美洲
	1003	珍妮	12	德国	9.0 	欧洲

不像数据库的主键，一个数据帧DataFrame的索引可以有重复，但在这种情况下，查找值可能比较慢。
要将一个索引转换成一个常规的列，可以用reset_index()函数；要设置新索引，用set_index()函数。
如果你不想在设置新索引时丢失现有索引，请确保现先将其重置：

In [7]: # "reset_index" 转换一个索引为一列，重置索引为缺省索引。这对应于一开始我们从Excel加载的数据帧。
	df.reset_index()

In [8]: # "set_index" 转换 “姓名”列为索引。
	df.reset_index().set_index("姓名")

Out[8]: 	用户ID	年龄	国家	分数	大陆

	姓名
	马克	1001	55	意大利	4.5	欧洲
	约翰	1000	33	美国	6.7	美洲
	提姆	1002	41	美国	3.9	美洲
	珍妮	1003	12	德国	9.0	欧洲

通过执行df.reset_index().set_index("姓名")，你使用的是方法链接：
由于reset_index()返回一个数据帧，你可以直接调用另一个数据帧方法，
而不必先写出中间结果。

**数据帧方法返回拷贝**
无论什么时候，你以“数据帧.方法名()”的形式调用数据帧上的一个方法，你
都会获得一个数据帧的副本，而原始数据帧保持不变。我们刚刚通过调用
df.reset_index()做了这个事情。如果你想修改原始的数据帧，你需要将返回
值分配回原始变量，如下所示：

	df = df.reset_index()
	
因为我们没有这样做，这意味者你的变量df还是保留着它的原始数据。下一
个示例也会调用DataFrame方法，即不会修改原始的数据帧。

为了修改索引，使用重新索引reindex方法：

In [9]: df.reindex([999, 1000, 1001, 1004])

Out[9]:		姓名	年龄	国家	分数	大陆
	用户id
	999	NaN	NaN	NaN	NaN	NaN

### 列

要取得数据帧的列信息，可以运行下列代码：

In [12]: df.columns
Out[12]: Index(['姓名', '年龄', '国家', '分数', '大陆'], dtype='对象')

如果在构造数据帧时，未提供提供任何列名，pandas会使用0开始的整数为列编号。
然而，对列来说，这几乎从来都不是一个好注意，因为列代表变量，因此很容易
命名。你可以使用与设置索引名称相同的方法来设置列头的名称：

In [13]: df.columns.name="属性"
	 df

如果你不喜欢这些列名，可以重命名他们：
In [14]: df.rename(columns={"姓名": "名字", "年龄": "年纪"})

如果想删除列，使用下面语法（这个例子向你展示如何同时删除列和索引）：

In[25]: df.drop(columns=["姓名","国家"], index=[1000, 10003])

数据帧的列和索引都由Index对象表示，因此你可以通过转换数据帧来，将列改为行，
反之亦然。

In [16]: df.T # Shortcut for df.transpose()

这里值得注意的是，我们的数据帧df依然是不变的，因为我们从没有将返回的数据帧从新分配
给原始的df变量。

如果你想将数据帧的列重排，你可以使用我们在索引上使用的reindex方法，但按所需的顺序选择列，往往会更直观：

In [17]: df.loc[:, ["大陆", "国家", "名称", "年龄", "分数"]]

最后一个例子，需要很多解释：关于loc数据选择工作原理的所有内容是下一章的主题。

## 数据操控

现实世界中的数据很难放在一个银盘上，所以在使用它之前，你需要清理它，并将它
转换成易于消化的形式。本章先介绍如何如何从一个数据帧中选择数据，如何更改
数据，如何处理丢失数据和重复数据。然后，我们将使用数据帧执行一些计算，并了解
如何如何使用文本数据。结束这部分时，我将会了解pandas何时返回视图，何时返回
副本。本节中的许多概念，都与我们上一章看到NumPy阵列相关。

#### 选择数据

让我们先从按标签和位置访问数据开始，然后再查看其它方法，包括布尔索引和使用
多索引选择数据。

##### 按标签选择数据

访问数据帧数据的最常见方法是引用其标签。使用loc属性（location的缩写），来
指定要检索的行列：

  df.loc[行选择， 列选择]
  
loc支持切片符号，因此接受使用一个冒号分别选择所有行或列。此外，你还可以
提供带标签的列表、一个单独的列名或行名。让我们看看表5-1，了解如何从示例
数据帧df中选择不同部分的一些例子。

表 5-1 按标签选择数据

选择		返回数据类型		例子

单值		标量			df.loc[1000, "国家"]
一列(1维)	序列Series		df.loc[:, "国家"]
一列(2维)	数据帧			df.loc[:, ["国家"]]
多列		数据帧			df.loc[:, ["国家", "年龄"]]
列区间		数据帧			df.loc[:, "姓名":"国家"]
一行(1维)	序列Series		df.loc[1000, :]
一行(2维)	数据帧			df.loc[[1000], :]
多行		数据帧			df.loc[[1003, 1000], :]
行区间		数据帧			df.loc[1000:1002, :]

**标签切片包含闭区间**
在标签中的切片表示法与Python和pandas中其他内容中的工作方式是不一致的：
它们包含上限值。

理解具有一列或多列数据帧和一个序列的差异对你来说很重要：即使只有一列，数据帧
也是二维的。数据帧和序列都有索引，但只有数据帧有列标题。当你选择一个列作为
序列时，列标题将成为序列的名称。许多函数或方法都能同时在序列和数据帧上工作，
但在执行数学计算是，行为会有所区别：对于数据帧，pandas会根据列的标题进行数据
对齐————本章稍后会做详细介绍。

**列选择的快捷方式**
由于列选择是一种常见操作，pandas提供了一个快捷方式。而不是：
  df.loc[:, 列选择]
你可以写：
  df[列选择]

例如：
  df["国家"]从示'''例数据帧中返回一个序列，
  df[["姓名", "国家"]]返回一个包含两列的数据帧。

#### 通过位置选择
按位置选择数据帧，与我们本章开头在NumPy阵列上做的操作相应。但是，对于数据帧，你必须使用iloc属性（integer 位置的缩写）：
  df.iloc[行选择，列选择]
使用切片时，你使用标准的半开区间。表5-2给出了我们之前在表5-1中看到的相同
案例。

图5-2 按位置选择数据

选择		返回数据类型		例子
单值		标量			df.iloc[1,2]
一列（一维）	序列			df.iloc[:, 2]
一列（二维）	数据帧			df.iloc[:, [2]]
多列		数据帧			df.iloc[:, [2, 1]]
区间列		数据帧			df.iloc[:, :3]
一行(1维)	序列			df.iloc[1, :]
一行(2维)	数据帧			df.iloc[[1], :]
多行		数据帧			df.iloc[[3,1], :]
行区间		数据帧			df.iloc[1:3], :]

按标签或位置选择数据不是访问数据帧子集的唯一方法。
另一个重要的方法是使用布尔索引。让我们看看它是如何工作的。

#### 通过布尔索引选择

布尔索引是指在只由True或False组成的序列或数据帧的帮助下，选择数据帧子集。
布尔序列用于选择特定的行和列，而布尔数据帧用于在整个数据帧中选择特定的值。

最常见的是，你会用布尔索引来过滤数据帧的行。可以将其视为Excel的AutoFilter
自动过滤功能。例如，这是你如何你的数据帧，使它仅返回居住在美国且年龄超过40岁的人。

In [24]: tf = (df["年龄"] > 40) & (df["国家"] == "美国")
	 tf # 这个返回的是一个只有真/假值的序列。
	
Out[24]: user_id
	 1001	False
	 1000	False
	 1002	True
	 1003	False
	 dtype: bool 

In [25]: df.loc[tf, :]
Out[25]: 属性		姓名	年龄	国家	分数	大陆
	 用户ID
	 1002		提姆	41	美国	3.9	美洲

这里有两件事是我需要在这里说明的。第一件事是，由于技术上的限制，你不能将第3章中的
Python布尔运算符应用于数据帧上，相反，你需要使用如表5-3所示的符号。

表5-3。布尔操作符

Python基础数据类型	数据帧和序列

and			&

or			|

not			！

第二，如果你有多个条件，请确保把每一个布尔表达式放在括号之间。
这样运算符优先级就不会妨碍你。例如：& 的优先级要高于==。 
因此，如果没有括号，上面例子的表达式就会被解析为下面这样：
	df["年龄"] > (40 & df["国家"]) == "USA"

如果你希望过滤索引，你可以引用df.index：

In[26]:	df.loc[df.index > 1001, :]

对于你在Python基础数据结构中使用的in操作符，你在序列Series中需要使用isin。

以下向你展示如何过滤你的数据帧以获得意大利和德国参与者。

In[27]: df.loc[df["国家"].isin(["意大利", "德国"]), :]

当你使用loc来提供一个布尔序列时，DataFrame提供了一个特殊的语法用来选择值，在给定完整布尔数据帧的情况下。

df[布尔数据帧]

这是非常有帮助的，如果你有数据帧，仅由数字组成。
提供一个布尔数据帧，会返回一个在布尔数据帧值为False的位置上具有NaN（Not a Number）值的数据帧。

同样，关于NaN的更明细的讨论会放在稍后。

让我们来创建一个叫rainfall的仅由数值构成的数据帧。
rainfall是降雨量的意思。

In [28]: # 这可能是以毫米millimeters为单位的年度降雨量。
	rainfall = pd.DataFrame(data={
		"城市1": [300.1, 100.2],
		"城市2": [400.3, 300.4],
		"城市3": [1000.5, 1100.6]})
	rainfall

Out[28]: 	城市1	城市2	城市3
	0	300.1	400.3	1000.3
	1	100.2	300.4	1100.6

In [29]: rainfall < 400
	#返回的是一个布尔数据帧


Out[29]: rainfall[rainfall < 400]
	#这里rainfall < 400, 这个"< 400" 运算会应用到数据帧的每一个元素上。
	元素与400的比较结果会填写到返回的数据帧的对应位置中。
	
	返回的结果帧，将具有原数据帧相同的行列标签。

	railfall[rainfall < 400]
	中括号有这个索引的意思，
	我们将中括号前的数据帧称为操作目标数据帧。
	在中括号提供一个和目标数据帧大小相同的布尔数据帧，
	就是指示目标数据帧根据布尔数据帧进行相同位置的元素筛选。

注意，在这个例子中，我用来一个字典来构造了一个新的数据帧。
如果数据已经是以这种形式存在的，这通常是方便快捷的方式。
以这种方式使用布尔值，通常是用来过滤特定的值，例如异常值。

作为本章都收尾，我将介绍一种特殊的索引类型叫做多索引。

#### 使用多重索引进行选择
一个多重索引是多级别索引。它允许按层次组装你的数据，并使你很轻松访问
数据子集。例如，如果你设置数据帧的索引为大陆和国家的子集，你可以很轻
松地选择具有具有特定大陆的所有行：

In [31]:# 多重索引需要进行排序
	df_multi = df.reset_index().set_index(["大陆", "国家"])
	df_multi = df_multi.sort_index()
	df_multi
	# 这样子处理下来，大陆和国家这列会变成索引列来展示。
	# 原来的索引会变成普通列。
	# 展示的结果集还会进行分组，相同层次下的记录只会有第一条
	# 记录展示父节点的索引值，其它都会省略。

Out[31]:属性		用户id	姓名	年龄	分数
	大陆	国家	
 	美洲	美国	1000	约翰	33	6.7
		美国	1002	提姆	41	3.9
	欧洲	德国	1003	珍妮	12	9.0
		意大利	1001	马克	55	4.5

In [32]:df_multi.loc["欧洲", :]

Out[32]:属性	用户id	姓名	年龄	分数
	国家
	德国	1003	珍妮	12	9.0
	意大利	1001	马克	55	4.5

注意，pandas通过不重复最左边的索引级别(大陆)来美化多索引输出。
相反，它只在大陆发生变化时打印。

使用元组在多索引级别上进行选择： 
In [33]: df_multi.loc[("欧洲", "意大利"), :]
Out[33]: 属性		用户id	姓名	年龄	分数
	 大陆	国家
	 欧洲	意大利	1001	马克	55	4.5
	
数据帧的reset_index有个很有意思的特性，就是它会将被重置掉的
索引转换成列在数据帧中保存。如果没有调用reset_index就执行set_index
原来的索引数据将会在执行完set_index后丢失。

如果想要有选择地重置一个多索引的一部分，请提供级别作为参数。
零是最左侧的第一列：

In [34]: df_multi.reset_index(level=0)
Out[34]: 属性	大陆	用户id	姓名	年龄	分数
	 国家
	 美国	美洲	1000	约翰	33	6.7
	 美国	美洲	1002	提姆	41	3.9
	 德国	欧洲	1003	珍妮	12	9.0
	 意大利	欧洲	1001	马克	55	4.5
	 
虽然在本书中，我们不会手动创建多索引，但有一些操作，像groupby，
会导致数据帧返回一个带索引的数据帧，因此最好知道他是什么。
我们将在本章后面与groupby会面。

既然你已经了解了选择数据的各种方式，现在就可以学习如何改变数据。

### 设置数据

更改数据帧数据的最简单方式是使用loc和iloc属性为特定的元素赋值。
在我们转向处理数据帧的其他方式前，这是本节起始点：替换值和添加列。

#### 通过标签和位置设置数据
正如在本章先前指出的，当你调用数据帧方法（如df.reset_index()）时，
该方法将始终应用于副，而原数据帧将维持不变。

但是，通过loc和iloc属性赋值会改变原始数据帧。
因为我想保留我们原始的数据帧不变，所以，我正在使用一个我称为df2的
副本。如果你要改变单个值，做以下操作：

In [35]: # 首先复制数据帧，使原始数据帧保持不变
	 df2 = df.copy()
	
In [36]: df2.loc[1000, "姓名"] = "JOHN"
	 df2
	 
Out[36]: 属性	姓名	年龄	国家	分数	大陆
	 用户ID
	 1001	马克	55	意大利	4.5	欧洲
	 1000	JOHN	33	美国	6.5	美洲
 	 1002	提姆	41	美国	3.9	美洲
	 1003	珍妮	12	德国	9.0	欧洲

也可以同时改变多个值。更改ID为1000和1001的用户分数的一种方法是使用
列表：

In [37]: df2.loc[[1000, 1001], "分数"] = [3, 4]
	 df2
	# 执行完这个你会发现数据帧的索引值为1000和1001的值发生了改变
	  索引值为1000的行的“分数”列的值更改成了3。
	  索引值为1001的行的“分数”列的值更改成了4。

通过iloc按位置更改数据的方式相同。现在让我们继续了解如何使用布尔索引
更改数据。

### 通过布尔索引设置数据

用来过滤行的布尔索引也可以用来在数据帧中赋值。设想以下你需要匿名说出20
岁以下或来自美国的人的匿名：

In [38]: tf=(df2["年龄"] < 20) | (df2["国家"] == "美国")
	 df.loc[tf, "姓名"] = "xxx"
	 df2

你会看到df2中年龄小于20或国家等于美国的行的姓名列的值都被更改为了xxx。

有些时候，你有一个数据集，需要全面替换其中的某些值。即，不特定于某些列。
在这种情况下，再次使用特殊语法，并为整个数据帧提供如下布尔值（示例还是
使用rainfall 数据帧）：

In [39]: rainfall2 = rainfall.copy()

In [40]: rainfall2[rainfall2 < 400] = 0
	 # 这个就是特殊语法了，以一个布尔数据帧作为索引，进行赋值。

如果你只是想用一个值替换另一个值，那么有更简单的方法。

#### 通过替换值来设置数据

如果你要在整个数据帧或选定的列中替换某个值，可以用replace方法。

In [41]: df2.replace("美国", "U.S.")
	# 执行完这个方法后，你会发现数据帧中所有值为“美国”的值都被替换成"U.S."了。
	# 这是是全数据帧替换的语法。

反之，如果你只是想在“国家”列上操作，你可以使用以下语法：

	df2.replace({"国家": {"美国": "U.S."}})
	#这个replace的语法结构有点意识个

在这种情况下，因为“美国”只出现在国家列中，因此它产生相同的结果与前一个例子一样。
在结束本章前，让我们看看如何往数据帧中添加列。
	
#### 通过添加列来设置数据

要向表中添加新列，直接向新列名赋值就好了。
例如，你可以使用标量或数组来向数据帧添加一个新列。

In [42]: df2.loc[:, "折扣"] = 0
	 df2.loc[:, "price"] = [49.9, 49.9, 99.9, 99.9]
	 df2
	 # 如果采用列表形式的列赋值，列表的长度必须与行数相同。
	 # 这里有个很好玩的事情。
	 # [索引] = 值， 整个整体对应一个函数，而不是像c++一样，中括号。
	 # 这就解释了，为什么调用df.loc[:, "新列名"]会报错，
	 # 但调用df.loc[:, "新列名"] = 值，不会报错。
	 # 一个函数，等号一个函数，这样就不用向C++一样处理左右值引用的问题。
	
添加一个新列通常涉及矢量化计算，例如：

In [43]: # 先复制一下
	 df2 = df.copy()
	 # 然后再插入一个生日列，生日 = 2021 - df2.loc[:, "年龄"]
	 # 化简的形式就是 2021 - df2["年龄"]
	 df2.loc[:, "生日"] = 2021 - df2["年龄"]
	 df2
	 
稍后，我将向你展示更多关于使用数据帧进行计算的内容，但在我们开始之前，
你还记得我已经使用过NaN几次么？下一节，将最终为你提供有关缺少数据主题的
更多上下文。

### 缺少的数据

缺少数据可能是一个问题，因为它有可能使数据分析的结果产生偏差，从而使你的结论
不那么可靠。尽管如此，在你的数据集中存在缺口是非常常见的，你将不得不处理这些
缺口。在Excel中，你通常需要处理#N/A（不是一个数字）错误，但pandas使用NumPy的
nan（not a number）表示缺失的数据，显示为NaN。NaN 是非数字的浮点标准。
对于时间戳，使用pd.NaT， 而对于文本，pandas使用None。使用None或np.nan，可以
引入缺失数据：

In [44]: df2 = df.copy()
	 df2.loc[1000, "分数"] = None
	 df2.loc[1003, :] = None
	 df2
	 # 因为“分数”列是个数值列，所以当你设置"分数"列为None时，实际上数据帧会把"分数"列设置为np.nan。
	 # 在这里我又想起了loc，和iloc的区别到底是什么？
	 # iloc 是 integer location indexer 的缩写，表示整型位置索引器
	 # iloc 的中括号__set_item__运算符中使用的是整型位置区间，而location indexer中使用的是
	 # 索引区间（列名列表也是个索引）

 要清洗一个数据帧，通常需要删除缺少数据的行。这很容易： 

 In [45]: df2.dropna()
 	  # 执行完后， df2中所有有缺失数据的行都删除了。
	  # 不过我有点好奇是会清理有缺失数值类型值的行而已，
	  # 还是全部(已经尝试过了，只要是有缺失值存在，都会删除)

 但是，如果你只想删除缺少所有值的行，可以使用how参数。
 给dropna提供 how="all"即可。
 
 In [46]: df2.dropna(how="all")

 Out[45]: # 数据帧还提供了获取一个是否是缺失值的布尔数据帧

 要根据是存在空值，获取一个数据帧或序列，可以使用isna方法。

 In [47]: df2.isna()

 要填充缺失值，请使用fillna函数。例如，要使用均值mean替换分数列的空值。（我很快就会介绍描述性统计函数，如mean（均值））：
 
 大概是这样子的：

 In [49]: df2.fillna({"分数": df2["分数"].mean()})

 我们会看到约翰分数列缺失的值被补上了。

数据缺失不是我们需要清理数据集的唯一条件，重复数据也是因此让我们看看我们的选项是什么。

### 重复数据
与缺失数据一样，重复数据会对你分析的可靠性产生负面的影响。为了去除重复列，
需要使用drop_duplicates方法。你可以提供一个列子集作为参数：

In [49]: df.drop_duplicates(["国家", "大陆"])
这条语句会将过国家和大陆重复的行，给删除了。这个挺好玩的，这个应该是删除其他行，保留第一出现的行。

默认情况下，这会保留第一次出现的行。要查明某列是否包含重复项，或获取其唯一值，需要使用下列两个命令（
如果你想在索引上运行此命令，使用df.index替代df["国家"]):

In [50]: df["国家"].is_unique

In [51]: df["国家"].unique()

最后，要了解哪些行是重复的，需要使用duplicated方法，该方法会返回一个布尔序列：
默认情况下，它会使用参数keep="first"，该参数保留第一次出现的行，并仅将重复的行标记为True。
通过设置参数keep=False，它将为所有行返回true（包括第一次出现的行）。从而很容易获得包含所有重复
行的数据帧。在下面的例子中，我们查看“国家”列中的重复项，但实际上，你经常会查看索引或整列，
在这种情况下，你必须使用df.index.duplicated() 或 df.duplicated():

一旦你通过删除缺失和重复数据来完成数据帧的清理，你可能会想执行一些算术运算————下一节将介绍如何
执行这些这些运算。

### 算术运算
和NumPy阵列一样，数据帧和序列也使用矢量化。例如：要向降雨数据帧中的每一个值添加一个数字，只需执行
以下操作：

In [54]: rainfall

In [55]: rainfall + 100

然而，pandas的真正力量是它的数据对齐机制。
当你在多个数据帧上进行算术计算的时候，pandas会自动根据他们的列和行索引对齐它们。
让我们使用一些相同的行和列标签创建第二个数据帧，然后求和：

# 我们会使用数据帧的构造函数DataFrame创建一个新的数据帧。
# 为了使第二个数据帧与第一个数据帧在结构上完全相同
# 我们会同时指定data， index， columns这三个参数。
# 第一个参数是数据，用于指定数据帧的数据。
# 这个数据是以嵌套列表的方式提供的。数据是行优先的方式提供的。
# 即列表的第一层中的每一个单元是行数据。第二层中，每一个元素是列值。
# 我们还要为这个数据帧提供行索引
# 还有什么？列标签列表。

这样子之后，构造了一个与第一个数据帧有部分列和部分行相同的数据帧。

如果在这两个数据帧上执行加法会怎样？

  城市1	城市2 城市3         城市1 城市4
0 400.1 500.3 1100.5    + 1 100   200
1 200.2 400.4 1200.6      2 300   400

rainfall + more_rainfall
得到的数据帧会是怎样的呢？
得到的数据帧的索引和列会是两个数据帧的并集。
在两个数据帧中都有值的字段，会显示其总和，其余的都会显示NaN。

这个为什么这么奇怪的呢？如果一个域在其中一个数据集这不存在，直接不加按0处理不就好了么。
这应该是pandas设计的底层逻辑导致的。
pandas是设计来做科学计算的。在科学计算中对数据的质量要求是很高的，
NaN不是一个合理的值，因此不应该参与任何运算。
所以只要有一个值为NaN就输出NaN。
+号运算符其实对应函数add。如果pandas的缺省行为不是你想要的，比如你想让
NaN的域也参与运算。可以直接用add方法，add方法有个fill_value的参数。
可以为值为NaN的域填充缺省值。


这个也适用于表5-4所示的其他算术运算符。

表 5-4 算术运算符
操作符	方法
*	mul
+	add
-	sub
/	div
**	pow

当你的计算中包含数据帧和序列时，默认情况下，序列会沿着索引广播：

广播是一种数据的扩散方式。

In [59]: rainfall.loc[1, :]
这条语句是获取第一行的所有域的值，返回一个序列。
然后打印出来，原来横着的数据就变成竖了。
列标签变成了索引（行标签）。

源数据帧

	City1	City2	City3
0	300.1	400.3	1000.5
1	100.2	300.4	1100.6

筛选出来的序列

City1	100.2
City2	300.4
City3	1100.6

railfall + railfall.loc[1, :]

这个得到的会是什么，数据是怎么广播出去的？

pandas是有自动对齐机制的。

我们先来看看这两个数据帧的可能的业务意义是什么？

第一个可能每年的，不同城市的降雨量汇总。

第二个可能是不同城市的降雨量调整值。

那么这两个数据帧应该如何执行加法运算呢？

第二个序列首先需要进行旋转与第一个数据帧的列进行对齐，
然后将第一行广播到第一个阵列的每行上，使两个数据帧兼容。

当你有一个数据帧和序列在你的计算中，缺省是沿着索引广播的。

这是什么意思？

我看了看数据帧的add方法的原型，里面有个axis参数，它的缺省值是columns。
再结合我看到的rainfall + rainfall.loc[:, "城市2"]的结果（是个NaN数据帧）
这个axis参数实际是表示要添加的序列对应数据帧的维度问题。
如果axis=1,或者"column"，表示要添加的序列对应的列轴上的一行数据。
原始数据帧可以按列标签将数据进行对齐，然后沿索引方向对序列数据进行垂直广播。

如果是加上一个行序列数据呢？也就是序列的每一项都是对应一个行索引的，然后数据需要进行列方向的广播。
这时候就不对了。如果数据帧把它当成一个列序列，就会匹配不到列名。按行索引垂直广播后，得到是将是是个NaN的数据帧，
根据pandas的规则原数据帧加上这个NaN数据帧自然得到的也是一个NaN数据帧。
那正确的玩法应该是什么呢？
我们应该告诉pandas，我们要添加的这个序列是行序列数据，这样，pandas就会对这个序列沿列轴进行广播。 

因此如果要按列方向添加序列，你需要使用带轴参数的add函数。

虽然本节是介绍数字数据帧及它们在算术运算中的行为的，但在下一节，将会向你介绍
在处理数据帧文本时的选项。

### 使用文本列

正如我们在本章开头看到的，具有文本或混合数据类型的列，具有“对象”数据类型。
要对包含文本字符串的列执行操作，需要使用str属性，这个属性会让你访问Python的字符串方法。
我们在第3章已经遇到了一些字符串方法，但看看Python 文档中的可用方法并没有什么坏处。
例如: 要移除前导空格和尾随空格，可以使用strip方法；为了让所有首字母大写，这里有capitalize方法。

将这些操作串在一起，可以清理干净混乱的文本列（这通常是手工输入导致的）。
In [10]: users = pd.DataFrame(data=["mArk", "JOHN", "Tim", "jenny"], columns=["name"])
	 users
这里有一个很有意思的问题，当你在data那填入的是一个嵌套列表时，
第一层的每个元素会被认为是行数据，第二层为每行每列的数据。
但是如果data是一维的，非嵌套的列表。data中的每一个元素又会被当成列数据。
pandas的思考逻辑是什么？pandas倾向于在没有上下文的场景下，同一列表的数据是同一类型。
最外一层依然面向行的数据，里面的每一列是列数据。

字符串方法很容易使用，但是有时你可能需要使用非内置的方式操作一个数据帧。
在这种情况下，你需要创建自己的函数并将其应用于数据帧，如下一节所示。

### 应用一个函数
数据帧提供了一个appymap 方法，可以应用一个函数到独立的元素。
如果没有NumPy的ufuncs，这是非常有用的功能。例如，如果没有字符串格式化的
ufuncs，我们可以像这样格式化数据帧的每一个元素，像这样：

我们把这件事拆分如下：
1. 下面的 f-string（格式化字符串），将x作为字符串返回：f"{x}"。
2. 添加格式，在变量后面添加一个冒号，再加上"，.2f"格式化串。 
3. 逗号是千分位分隔符，.2f表示小数点后面有两位数的定点表示法。
要获得关于如何格式化字符串的信息，请参考“格式化规范迷你语言”，
它是Python文档的一部分。

对于这种用例，lambda（匿名）表达式被广泛使用，因为它们允许你在一行里写同样的功能
而无需定义一个独立的函数。使用lambda表达式，我们可以将前面的示例重写为：

rainfall.applymap(lambda x: f"{x:,.2f}")

**lambda表达式**
Python允许你通过lambda表达式在单行定义一个函数。Lambda表达式就是匿名函数。
这意味着它是一个没有名的函数。思考这个函数：
def 函数名(参数1, 参数2, ...):
	return 返回值
这个函数可以重写成如下的lambda表达式：
	lambda 参数1, 参数2, ...: 返回值
本质上，就是用lambda关键字替换def，去掉了return关键字。
就像我们在applymap方法中看到的，这样真的很方便，因为我们无需
为只使用一次的东西定义一个函数。

我现在已经提及到了所有重要的数据操作方法，但在我们继续之前，了解pandas何时使用数据帧的视图，
何时使用副本是很重要的。

#### 视图还是副本

你可能还记得在NumPy阵列上执行切片操作时，会返回一个视图。
不幸的是，对于数据帧，它更为复杂：对于loc和iloc会返回视图还是副本，
并不是总是容易预测的，这使它成为一个更为令人困惑的话题。
由于你是在修改数据帧视图还是在修改数据帧副本有很大区别，
当pandas认为你是在以无意的方式在设置数据时，经常会抛出一个警告：
SettingWithCopyWarning。为了避免这个相当隐晦的警告，这里有一些建议：

* 在原始数据帧上设置值，而不是在一个从另一个数据帧上切片下来的数据帧上设置值。
* 如果你希望切片后有个独立数据帧，请显示使用copy方法：
虽然loc和iloc的情况很复杂，但是值得记住的是，所有数据帧的方法，像df.dropna()
和df.sort_values("列名")总是会返回一个副本。

目前为止，我们大多数时间都是一次操作一个数据帧。下一节，将向你展示多种合并数据帧的方法，
pandas为这项非常常见的任务提供了强大的工具。

#### 组合数据帧
在Excel中组合不同数据集是可能是一件繁琐的，通常涉及了很多VLOOKUP公式。
幸运地是，组合数据帧是pandas的一项杀手级功能，它的数据集对齐功能将使你的生活变得非常轻松，
从而极大地减少了引入错误的可能性。组合和合并数据帧可以通过多种方式完成。本节仅会介绍使用
concat，join，merge的最常用情况。虽然它们的功能有重叠，但是每一个函数都使得一个特定的任务变得
非常容易。我将从concat函数开始，然后解释join函数的不同选项，最后介绍merge，这三个函数
中最有用的一个。

##### Concatenating连接
只是要简单地把两个数据帧粘合在一起，concat方法是你最好的朋友。从函数名可以看出，这个过程
有个技术名称叫串联。缺省情况下，cancat会沿着行将数据帧粘合在一起，并自动对齐列。
在下面列子中，我会创建另一个叫more_users的数据帧，并将其附加到我们示例数据帧df的底部。

注意，你现在有重复索引元素，因为concat是沿着指定轴（行）将数据粘起来的，并只在另一轴（列）对数据进行对齐，
从而自动匹配列名，即使它们在两个数据帧中的顺序是不同的。如果要沿列将两个数据帧粘贴在一起，
请设置axis=1：

concat一个特殊和有用的特性是它可以接受两个以上的数据帧。我们将使用这个特性从多个csv文件中生成一个独立的数据帧。

pd.concat([df1, df2, df3, ...])

另一方面，join和merge函数只适用于两个数据帧，就像我们将要看到的。

##### 整合和合并
当你join（联合）两个数据帧时，会融合两个数据帧的列，并根据集合原理决定如何处理行。
如果你以前使用过关系数据库，它和SQL查询中的JOIN子句是一个概念。
整合类型有（Inner内整合、左整合、右整合、外整合）。

为什么叫内整合呢？因为逻辑上来说，这两个数据帧都可以认为是行数据的集合。
内整合就是两个集合放在一起，求中间重叠的部分。这个重叠的部分就是内部。整合后的列会是两个原始数据帧的列合并。
左整合就是要左边一个集合的全部部分，如果右边的集合中包含左边集合相同索引的行，行中的列数据会合并到目标数据帧中。

使用Join，pandas会使用索引对齐两个数据帧的行。内部联合只返回包含索引重叠的行的数据帧。
左联合会获取左数据帧df1的所有行，并在索引上匹配右数据帧的行。如果df2中没有匹配的行。pandas将填NaN。
左联合对应Excel中的VLOOKUP情景。右联合从右数据帧df2中获取所有的行并用索引匹配df1中的行。
最后，外部连接，是全外部连接的缩写。它从两个数据帧中获取索引的并集，并尽可能匹配值。

表5-5是图5-3的等价文本形式

Inner内联合 返回两边数据帧都存在索引的行。
Left左联合  返回左边数据帧所有的行，并匹配右边数据帧的行。
Right右联合 返回右边数据帧所有的行，并匹配左边数据帧的行。
Outer外联合 返回两边数据帧行索引的并集。

df1.join(df2, how="outer")
df1.join(df2, how="inner")
df1.join(df2, how="left")
df1.join(df2, how="right")

如果你想在一个或多个数据帧列上联合数据帧，而不是依赖索引，你需要使用
merge方法，而不是join。merge接受on参数提供的一个或多个列作为联合条件，
这些列必须同时存在在两个数据集上面，用于行匹配：

因为join和merge接受相当多的参数用于适应更复杂的场景，我邀请你查看官方文档，以更了解它们。
你现在知道了如何操作一个或多个数据帧，这将带我们进入数据分析的下一旅程：让数据变得有意义（make sense of data), 理解数据。

## 描述性统计和数据聚合

理解大型数据集的一种方法是计算整个数据集或有意义的子集的一个描述性统计，如总和或平均值。
本章首先介绍pandas的工作原理，然后介绍将数据聚合到子集的两种方法：groupby（分组by）和pivot_table（透视表）函数。

### 描述性统计

描述性统计允许你使用定量度量来汇总数据集。例如，数据点的数量就是一个简单的描述性统计。平均的数，像平均值mean，中位数median，或模式mode
是其他流行的例子。数据帧和序列允许你通过sum，mean，count等方法，方便地访问描述性统计数据。在本书中你会遇到其中的很多函数，完整的列表可以
通过pandas的文档获取。
默认情况下，它们返回一个沿索引轴统计的序列，这意味着你能获得列的统计信息：
rainfall.mean()
如果你想沿列统计，需要提供axis参数。
rainfall.mean(axis=1)

默认情况下，缺失数据不会被包含在描述性统计信息中（像sum或mean）。这与Excel处理空单元格的方式一致。因此在包含空单元格的区间上使用Excel的平均值公式，
你会获得应用于具有相同数字和NaN值序列上的mean方法相同的值。(说白了，就是会忽略包含空值的项）

在数据帧所有行中获取一个统计数据，有时不够好，你需要更细粒度的信息——例如，每个分类的平均值。
让我们看看，我们是如何做到的。

### 分组

让我们再次使用我们的示例数据帧，让我们找出每个大陆的平均分。为此，你首先需要按大陆对行进行分组，然后应用mean方法。
该方法会计算每组的平均值。所有非数值列都自动排除了：

df.groupby(["大陆"]).mean()

如果你包含多个列，则生成的数据帧会有一个层次索引————我们前面遇到的多索引。

df.groupby(["大陆", "国家"]).mean()


